{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOge25dTbUiqrFCVDlskanc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZzzMirror/next_day_wildfire_spread/blob/master/LSTM_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/*.tfrecord\n",
        "file_path = '/content/*.tfrecord'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfIxGwTZabnp",
        "outputId": "160cce51-0633-4a08-bfd9-8fb7244ca4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/next_day_wildfire_spread_eval_00.tfrecord\n",
            "/content/next_day_wildfire_spread_eval_01.tfrecord\n",
            "/content/next_day_wildfire_spread_train_00.tfrecord\n",
            "/content/next_day_wildfire_spread_train_01.tfrecord\n",
            "/content/next_day_wildfire_spread_train_02.tfrecord\n",
            "/content/next_day_wildfire_spread_train_03.tfrecord\n",
            "/content/next_day_wildfire_spread_train_04.tfrecord\n",
            "/content/next_day_wildfire_spread_train_05.tfrecord\n",
            "/content/next_day_wildfire_spread_train_06.tfrecord\n",
            "/content/next_day_wildfire_spread_train_07.tfrecord\n",
            "/content/next_day_wildfire_spread_train_08.tfrecord\n",
            "/content/next_day_wildfire_spread_train_09.tfrecord\n",
            "/content/next_day_wildfire_spread_train_10.tfrecord\n",
            "/content/next_day_wildfire_spread_train_11.tfrecord\n",
            "/content/next_day_wildfire_spread_train_12.tfrecord\n",
            "/content/next_day_wildfire_spread_train_13.tfrecord\n",
            "/content/next_day_wildfire_spread_train_14.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqM3_2UYYRor"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定义特征"
      ],
      "metadata": {
        "id": "Kbnp0JpXho_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义特征\n",
        "feature_description = {\n",
        "    'vs': tf.io.VarLenFeature(tf.float32),\n",
        "    'NDVI': tf.io.VarLenFeature(tf.float32),\n",
        "    'erc': tf.io.VarLenFeature(tf.float32),\n",
        "    'PrevFireMask': tf.io.VarLenFeature(tf.float32),\n",
        "    'FireMask': tf.io.VarLenFeature(tf.float32),\n",
        "    'sph': tf.io.VarLenFeature(tf.float32),\n",
        "    'th': tf.io.VarLenFeature(tf.float32),\n",
        "    'pr': tf.io.VarLenFeature(tf.float32),\n",
        "    'population': tf.io.VarLenFeature(tf.float32),\n",
        "    'tmmx': tf.io.VarLenFeature(tf.float32),\n",
        "    'pdsi': tf.io.VarLenFeature(tf.float32),\n",
        "    'elevation': tf.io.VarLenFeature(tf.float32),\n",
        "    'tmmn': tf.io.VarLenFeature(tf.float32)\n",
        "}"
      ],
      "metadata": {
        "id": "hAZPc49eYaLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA_STATS ，包含每个特征的统计数据（最小值、最大值、均值、标准差）\n",
        "DATA_STATS = {\n",
        "    'elevation': (0.0, 3141.0, 657.3003, 649.0147),\n",
        "    'th': (0., 360.0, 190.3298, 72.5985),\n",
        "    'vs': (0.0, 10.0243, 3.8501, 1.4110),\n",
        "    'tmmn': (253.15, 298.9489, 281.08768, 8.9824),\n",
        "    'tmmx': (253.15, 315.0923, 295.17383, 9.8155),\n",
        "    'sph': (0., 1., 0.0071658953, 0.0042835088),\n",
        "    'pr': (0.0, 44.5304, 1.7398051, 4.4828),\n",
        "    'pdsi': (-6.1298, 7.8760, -0.0053, 2.6823),\n",
        "    'NDVI': (-9821.0, 9996.0, 5157.625, 2466.6677),\n",
        "    'population': (0., 2534.0630, 25.5314, 154.7233),\n",
        "    'erc': (0.0, 106.2489, 37.3263, 20.8460),\n",
        "    'PrevFireMask': (-1., 1., 0., 1.)\n",
        "}"
      ],
      "metadata": {
        "id": "sprBptAdjRml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W5xZCp6khxqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 解析函数"
      ],
      "metadata": {
        "id": "tEf52-vfhyu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(serialized_example):\n",
        "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
        "    features = {k: tf.sparse.to_dense(v) for k, v in example.items() if k != 'FireMask'}\n",
        "    label = tf.sparse.to_dense(example['FireMask'])\n",
        "    return features, label"
      ],
      "metadata": {
        "id": "F32uGHqVhuYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "解析函数测试："
      ],
      "metadata": {
        "id": "Ghs_yzMOiFV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_parse_tfrecord():\n",
        "    # 创建一个模拟的 TFRecord 示例\n",
        "    feature = {\n",
        "        'vs': tf.train.Feature(float_list=tf.train.FloatList(value=[1.0, 2.0])),\n",
        "        'NDVI': tf.train.Feature(float_list=tf.train.FloatList(value=[0.5])),\n",
        "        'FireMask': tf.train.Feature(float_list=tf.train.FloatList(value=[0, 1]))\n",
        "    }\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "    serialized_example = example.SerializeToString()\n",
        "\n",
        "    # 解析模拟的 TFRecord\n",
        "    parsed_features, parsed_label = parse_tfrecord(serialized_example)\n",
        "\n",
        "    # 检查解析的结果\n",
        "    print(\"Features:\", parsed_features)\n",
        "    print(\"Label:\", parsed_label)\n",
        "\n",
        "# 定义解析函数\n",
        "feature_description = {\n",
        "    'vs': tf.io.VarLenFeature(tf.float32),\n",
        "    'NDVI': tf.io.VarLenFeature(tf.float32),\n",
        "    'FireMask': tf.io.VarLenFeature(tf.float32)\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# 运行测试\n",
        "test_parse_tfrecord()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpSSG9hcZ07I",
        "outputId": "4f140759-eef5-4b39-b15c-4ad3c2cd0bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: {'NDVI': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.5], dtype=float32)>, 'vs': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>}\n",
            "Label: tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 加载数据集并创建数据"
      ],
      "metadata": {
        "id": "hzSaeC0Uh3qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path):\n",
        "    # 使用 tf.io.gfile.glob 解析包含通配符的路径\n",
        "    files = tf.io.gfile.glob(file_path)\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No files matched the pattern: {}\".format(pattern))\n",
        "\n",
        "    # 创建数据集\n",
        "    raw_dataset = tf.data.TFRecordDataset(files)\n",
        "    parsed_dataset = raw_dataset.map(parse_tfrecord)\n",
        "    return parsed_dataset\n",
        "\n",
        "# 使用通配符加载多个文件示例\n",
        "train_dataset = load_dataset('next_day_wildfire_spread_train*')\n",
        "val_dataset = load_dataset('next_day_wildfire_spread_eval*')"
      ],
      "metadata": {
        "id": "fMTNRMsuaSJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "加载数据测试："
      ],
      "metadata": {
        "id": "ThQRVADGiLVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_dataset_and_guess_label_key(dataset):\n",
        "    for features, label in dataset.take(1):  # 只取一个批次\n",
        "        print(\"Feature shapes:\")\n",
        "        all_keys = features.keys()  # 获取所有键的列表\n",
        "        for key in all_keys:\n",
        "            print(f\"{key}: {features[key].shape}\")\n",
        "\n",
        "        # 打印标签的形状\n",
        "        print(\"Label shape:\", label.shape)\n",
        "\n",
        "        # 猜测 label_key\n",
        "        # 常用逻辑：标签字段可能是二元的、分类的，或者是区别明显的连续值\n",
        "        print(\"Potential label_key candidates based on common naming conventions:\")\n",
        "        for key in all_keys:\n",
        "            if \"label\" in key.lower() or \"target\" in key.lower() or \"mask\" in key.lower():\n",
        "                print(key)\n",
        "\n",
        "# 使用此函数查看数据集并猜测标签键\n",
        "inspect_dataset_and_guess_label_key(train_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZY6jZAImeS8",
        "outputId": "bb720d38-ab8a-4509-fd3c-fb75e4e71580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shapes:\n",
            "NDVI: (4096,)\n",
            "PrevFireMask: (4096,)\n",
            "elevation: (4096,)\n",
            "erc: (4096,)\n",
            "pdsi: (4096,)\n",
            "population: (4096,)\n",
            "pr: (4096,)\n",
            "sph: (4096,)\n",
            "th: (4096,)\n",
            "tmmn: (4096,)\n",
            "tmmx: (4096,)\n",
            "vs: (4096,)\n",
            "Label shape: (4096,)\n",
            "Potential label_key candidates based on common naming conventions:\n",
            "PrevFireMask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#输出数据集特征名称和类型\n",
        "import tensorflow as tf\n",
        "\n",
        "def print_features(tfrecord_file):\n",
        "    # Load one example from the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "    for raw_record in raw_dataset.take(1):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "        print(\"Feature names and data types in the TFRecord:\")\n",
        "        for key, feature in example.features.feature.items():\n",
        "            # Print the feature name and the data type of the feature\n",
        "            data_type = feature.WhichOneof('kind')\n",
        "            print(f\"{key}: {data_type}\")\n",
        "\n",
        "# Replace 'path_to_tfrecord.tfrecord' with the path to your TFRecord file\n",
        "print_features('/content/next_day_wildfire_spread_train_00.tfrecord')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYeMbo94rdOD",
        "outputId": "0c9c734f-947c-4721-f8af-785a6f30892d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature names and data types in the TFRecord:\n",
            "vs: float_list\n",
            "NDVI: float_list\n",
            "FireMask: float_list\n",
            "sph: float_list\n",
            "th: float_list\n",
            "pr: float_list\n",
            "PrevFireMask: float_list\n",
            "tmmn: float_list\n",
            "elevation: float_list\n",
            "tmmx: float_list\n",
            "pdsi: float_list\n",
            "erc: float_list\n",
            "population: float_list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_load_and_preprocess():\n",
        "    # 假设您已经有一个小的 TFRecord 文件用于测试\n",
        "    test_dataset = load_dataset(file_path)\n",
        "    for features, label in test_dataset.take(1):  # 只取一个批次进行验证\n",
        "        print(\"Batch features:\", features)\n",
        "        print(\"Batch labels:\", label)\n",
        "\n",
        "# 实际调用测试函数\n",
        "test_load_and_preprocess()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g330w1FAZ8HI",
        "outputId": "54170cc9-bff1-4d9b-e18a-e47a9fdb2337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch features: {'NDVI': <tf.Tensor: shape=(4096,), dtype=float32, numpy=array([5567., 5664., 5379., ..., 5162., 4169., 4169.], dtype=float32)>, 'vs': <tf.Tensor: shape=(4096,), dtype=float32, numpy=\n",
            "array([3.7468874, 3.7470345, 3.7470841, ..., 3.9530666, 3.9572198,\n",
            "       3.9624588], dtype=float32)>}\n",
            "Batch labels: tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(4096,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQ6_JLbki3pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据预处理"
      ],
      "metadata": {
        "id": "pyItJAfIi4Vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(features, label):\n",
        "    # 处理特征\n",
        "    features['NDVI'] = (features['NDVI'] + 10000) / 20000\n",
        "    features['tmmn'] -= 273.15\n",
        "    features['tmmx'] -= 273.15\n",
        "\n",
        "    for key in ['elevation', 'population', 'vs', 'sph']:\n",
        "        mean = DATA_STATS[key][2]  # mean均值\n",
        "        std = DATA_STATS[key][3]   # std标准差\n",
        "        features[key] = (features[key] - mean) / std\n",
        "\n",
        "    # 不需要从特征中提取标签\n",
        "    # label 已经作为独立参数传递\n",
        "\n",
        "    # 组合其它特征\n",
        "    feature_values = [features[key] for key in features if key in features]\n",
        "    features_tensor = tf.stack(feature_values, axis=-1)\n",
        "    return features_tensor, label\n"
      ],
      "metadata": {
        "id": "KZjm1Mwoi6al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 应用预处理和数据管道设置\n",
        "train_dataset = train_dataset.map(preprocess).batch(32).shuffle(buffer_size=1000).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(preprocess).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "uIXAxWXEtLCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_feature_names(dataset):\n",
        "    for features, label in dataset.take(1):  # 只取一个批次\n",
        "        # 假设 features 是一个字典\n",
        "        if isinstance(features, dict):\n",
        "            print(\"Feature names in the dataset:\")\n",
        "            for key in features.keys():\n",
        "                print(key)\n",
        "        else:\n",
        "            print(\"Features are not provided in a dictionary format.\")\n",
        "\n",
        "# 调用此函数查看训练和验证数据集的特征名称\n",
        "print_feature_names(train_dataset)\n"
      ],
      "metadata": {
        "id": "b1w925VEotAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 定义LSTM模型"
      ],
      "metadata": {
        "id": "IQrPyijHiQDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
        "        LSTM(50),\n",
        "        Dense(1, activation='sigmoid')  # 根据问题调整激活函数和输出层神经元数量\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 创建模型实例\n",
        "model = build_model((None, 12))  # None 表示任意时间序列长度\n"
      ],
      "metadata": {
        "id": "YR5wTshViTLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape):\n",
        "    model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=input_shape),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(128),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "    return model\n",
        "\n",
        "# 创建模型实例\n",
        "model = build_model((None, 12))  # None 表示任意时间序列长度\n"
      ],
      "metadata": {
        "id": "0pkPvo6bicrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 编译和训练模型"
      ],
      "metadata": {
        "id": "38h0x_FkidbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_dataset, epochs=3, validation_data=val_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PTOUmR6uig0z",
        "outputId": "189cf8ec-537b-4913-c61b-6b6449fe23eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DataLossError",
          "evalue": "Graph execution error:\n\nDetected at node IteratorGetNext defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-9-1266d0ec1a6c>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1383, in step_function\n\ntruncated record at 18771544' failed with Read less bytes than requested\n\t [[{{node IteratorGetNext}}]] [Op:__inference_train_function_5873]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1266d0ec1a6c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDataLossError\u001b[0m: Graph execution error:\n\nDetected at node IteratorGetNext defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-9-1266d0ec1a6c>\", line 2, in <cell line: 2>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1383, in step_function\n\ntruncated record at 18771544' failed with Read less bytes than requested\n\t [[{{node IteratorGetNext}}]] [Op:__inference_train_function_5873]"
          ]
        }
      ]
    }
  ]
}